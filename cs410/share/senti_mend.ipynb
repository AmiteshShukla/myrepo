{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENTI_MEND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A recommender utility that provides recommendation of relevent kid's books based on parent's rating and feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Senti_Mend requires python installation - if possible - on linux environment; although, it should work on other environments (mac, windows) given proper installation.\n",
    "\n",
    "For python installation, visit this site: http://docs.python-guide.org/en/latest/starting/installation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required python packages:\n",
    "\n",
    "**1. Make sure to install the following required python-based packages:**\n",
    "\n",
    "<block>\n",
    "<pre>\n",
    "    scipy (1.0.0)\n",
    " \n",
    "      $ pip install scipy\n",
    "   \n",
    "    nltk (3.2.5)\n",
    "\n",
    "      $ pip install nltk\n",
    "\n",
    "    sklearn-pandas (1.6.0)\n",
    "\n",
    "      $ pip install sklearn-pandas\n",
    "\n",
    "    subprocess32 (3.2.7)\n",
    "\n",
    "      $ pip install subprocess32\n",
    "\n",
    "    pandas (0.20.3)\n",
    "\n",
    "      $ pip install pandas\n",
    "\n",
    "    pandas-datareader (0.4.0)\n",
    "\n",
    "      $ pip install pandas-datareader\n",
    "\n",
    "    numpy (1.13.3)\n",
    "\n",
    "      $ pip install scipy\n",
    "   \n",
    "    hashlib (20081119)\n",
    "\n",
    "      $ pip install hashlib\n",
    "\n",
    "    toml (0.9.3)\n",
    "\n",
    "      $ pip install toml\n",
    "</pre>\n",
    "</block>\n",
    "      \n",
    "\n",
    "**2. For NLTK, there are extra downloads required. Cut and paste the following code into a file: my_nltk.py**\n",
    "\n",
    "<block>\n",
    "<pre>\n",
    "------- Start of python script ---\n",
    "import nltk\n",
    "import ssl \n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('all')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('wordnet')\n",
    "------- End of python script -------\n",
    "</pre>\n",
    "</block>\n",
    "\n",
    "**3. Then execute:**\n",
    "\n",
    "<block>\n",
    "<pre>\n",
    "$ python ./my_nltk.py\n",
    "[nltk_data] Downloading collection u'all'\n",
    "[nltk_data]    |\n",
    "[nltk_data]    | Downloading package abc to\n",
    "[nltk_data]    |     /Users/raymondordona/nltk_data...\n",
    "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
    "[nltk_data]    | Downloading package alpino to\n",
    "[nltk_data]    |     /Users/raymondordona/nltk_data...\n",
    "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
    "[nltk_data]    | Downloading package biocreative_ppi to\n",
    "[nltk_data]    |     /Users/raymondordona/nltk_data...\n",
    "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
    "...\n",
    "nltk_data]    | Downloading package mwa_ppdb to\n",
    "[nltk_data]    |     /Users/raymondordona/nltk_data...\n",
    "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
    "[nltk_data]    |\n",
    "[nltk_data]  Done downloading collection all\n",
    "</pre>\n",
    "</block>\n",
    "\n",
    "**Note:** Running nltk.download('all') may require close to 4GB of disk space.\n",
    "\n",
    "**4. Download senti_mend.py and senti_mend.conf**\n",
    "\n",
    "**5. Download Dataset.txt and Final_Feedback.txt**\n",
    "\n",
    "**6. Edit senti_mend.conf and update the path to the two datasets.**\n",
    "<block>\n",
    "<pre>\n",
    "   [dataset]\n",
    "   book = \"./dataset/Dataset.txt\"\n",
    "   rating = \"./dataset/Final_Feedback.txt\"\n",
    "   mask_rating = \"./dataset/Mask_Final_Feedback.txt\"\n",
    "\n",
    "   [tfidf]\n",
    "   max_features=3000\n",
    "   lemmatize_first=\"True\"\n",
    "   \n",
    "   [sentiment]\n",
    "   algo=\"vader\"  # other choices:  vader,swn\n",
    "\n",
    "</pre>\n",
    "</block>\n",
    "  Note: See Sentiment Analysis algorithm section for \"lemmatize_First\" parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\tTo list books (simulating listing book):\n",
    "\n",
    "\t\tsenti_mend.py -l\n",
    "\n",
    "\t\tNote: You can derive the <book id> of a book by running  senti_mend.py -l\n",
    "\n",
    "\tTo display book information:\n",
    "\n",
    "\t\tsenti_mend.py -i -t <book title|book id>\n",
    "\n",
    "\tTo search a book:\n",
    "\n",
    "\t\tsenti_mend.py -s -t <book title>\n",
    "\n",
    "\tTo check for recommended books based on given title:\n",
    "\n",
    "\t\tsenti_mend.py -c -t <book title|book id> [-d]\n",
    "\n",
    "\t\twhere [-d] is in debug mode\n",
    "\n",
    "\tTo rate a book (simulating click-throughs and feedback):\n",
    "\n",
    "\t\tsenti_mend.py -r <rate between 1 and 5> -t \"<book title|book id>\" -f \"<feedback>\" -u \"<user>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Tutorial:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First**, get a list of available books. To do this, run the following command:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<block>\n",
    "<pre>\n",
    "$ ./senti_mend.py -l\n",
    "                                                                               Title          Category\n",
    "0                          Trace Numbers, Ages 3 - 5 (Big Skills for Little Hands)                Math\n",
    "1                                                                           7 Ate 9               Math\n",
    "2                               Numbers: Ages 3-5 (Collins Easy Learning Preschool)               Math\n",
    "3                                                                      Feast for 10               Math\n",
    "4                                                              Chicka Chicka 1, 2, 3              Math\n",
    "5                            Maths Ages: Ages 4-5 (Collins Easy Learning Preschool)               Math\n",
    "6                                                      Sequencing & Memory Workbook               Math\n",
    "7                    Math Work Stations: Independent Learning You Can Count On, K-2               Math\n",
    "8                                             Common Core Connections Math, Grade K               Math\n",
    "9    Young Children's Mathematics: Cognitively Guided Instruction in Early Childh...              Math\n",
    "10                        Shapes, Grades PK - K: Gold Star Edition (Home Workbooks)               Math\n",
    "11                             What's the Place Value? (Little World Math Concepts)               Math\n",
    "12         Shapes, Colours and Patterns: Ages 3-5 (Collins Easy Learning Preschool)               Math\n",
    "13                     Numbers Workbook: Ages 3-5 (Collins Easy Learning Preschool)               Math\n",
    "...\n",
    "</pre>\n",
    "</block>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second**, get book information.  You can get information of a book by providing the book id or the book title. For example, to get book information using book id 6 for book title 'Sequencing & Memory Workbook', you can issue the following command:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<block>\n",
    "<pre>\n",
    "$ ./senti_mend.py -i -t 6\n",
    "\n",
    "Book Information:\n",
    "\n",
    "               **Id:** 6\n",
    "            **Title:** Sequencing & Memory Workbook\n",
    "           **Author:** by Brighter Child (Compiler),\n",
    "         **Category:** Math\n",
    "      **Description:** Carson-Dellosa Publishing (Compiler) Brighter Child Sequencing & Memory helps young children master thinking skills and concepts. Practice is included for numbers, patterns, classification, critical thinking, and more. School success starts here! Workbooks in the popular Brighter Child series are packed with plenty of fun activities that teach a variety of essential school skills. Students will find help for math, English and grammar, handwriting, and other important subject areas. Each book contains full-color practice pages, easy-to-follow instructions, and an answer key.\n",
    "</pre>\n",
    "</block>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or you also can use:  \n",
    "\n",
    "    $ ./senti_mend.py -i -t \"Sequencing & Memory Workbook\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Third**, try to search for a book title. Use the below command. Below, we are searching for book titles that matches for the **'Seq'** pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<block>\n",
    "<pre>\n",
    "$ ./senti_mend.py -s -t \"Seq\"\n",
    "Book Information:\n",
    "\n",
    "               **Id:** 6\n",
    "            **Title:** Sequencing & Memory Workbook\n",
    "           **Author:** by Brighter Child (Compiler),\n",
    "         **Category:** Math\n",
    "      **Description:** Carson-Dellosa Publishing (Compiler) Brighter Child Sequencing & Memory helps young children master thinking skills and concepts. Practice is included for numbers, patterns, classification, critical thinking, and more. School success starts here! Workbooks in the popular Brighter Child series are packed with plenty of fun activities that teach a variety of essential school skills. Students will find help for math, English and grammar, handwriting, and other important subject areas. Each book contains full-color practice pages, easy-to-follow instructions, and an answer key.\n",
    "</pre>\n",
    "</block>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fourth**, check if a book title has already been rated.  If a book is rated, a list of recommended books may also be available.  To get recommendation for all other books, use the following command:\n",
    "\n",
    "Below is a book that has not been rated yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<block>\n",
    "<pre>\n",
    "$ ./senti_mend.py -c -t 6\n",
    "\n",
    "===============================================================\n",
    "                      RECOMMENDATION\n",
    "===============================================================\n",
    "\n",
    "The sparsity level of Book Reviews is 97.8%\n",
    "\n",
    "Title:  Sequencing & Memory Workbook\n",
    "\n",
    "Book has not been rated yet ... No relevant titles to recommend\n",
    "\n",
    "To rate book:  senti_mend.py -r &lt;rate between 1 and 5&gt; -t \"&lt;book title|book id&gt;\" -f \"&lt;feedback&gt;\" -u \"&lt;user&gt;\"\n",
    "</pre>\n",
    "</block>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of a book with recommendation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<block>\n",
    "<pre>\n",
    "$ ./senti_mend.py -c -t 244\n",
    "\n",
    "===============================================================\n",
    "                      RECOMMENDATION\n",
    "===============================================================\n",
    "\n",
    "The sparsity level of Book Reviews is 97.8%\n",
    "\n",
    "Title:  Greek Myths for Young Children\n",
    "\n",
    "**Note:** The following books received positive score and positive feedback from parents\n",
    "      who also read the book (Greek Myths for Young Children)\n",
    "\n",
    "positives  score                                   title\n",
    "     18.0  1.000          Greek Myths for Young Children\n",
    "      7.0  1.000                        Beginning Sounds\n",
    "      2.0  1.000  Sensational Seasons: Reproducible Fall\n",
    "      7.0  0.875                       Same or Different\n",
    "</pre>\n",
    "</block>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally**, To rate a book and give a good review, use the following command:\n",
    "\n",
    "Here is a book that the user has already rated ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <block>\n",
    "<pre>\n",
    "$ ./senti_mend.py -r 5 -u \"raymond5\" -t \"Greek Myths for Young Children\" -f \"good book\"\n",
    "\n",
    "User (d196a91fb80e88) already rated the title (Greek Myths for Young Children)...\n",
    "</pre>\n",
    "</block>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is a book that another user has not rated yet ...\n",
    "\n",
    "<block>\n",
    "<pre>\n",
    "./senti_mend.py -r 5 -u \"raymond ordona\" -t \"Greek Myths for Young Children\" -f \"good book\"\n",
    "\n",
    "User review recorded:\n",
    "\n",
    "      Parent User: f03e434e8b7c5f (Hashed)\n",
    "       Book Title: Greek Myths for Young Children\n",
    "             Rate: 5\n",
    "         Feedback: good book\n",
    "</pre>\n",
    "</block>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "The goal is to be able to interprete a comment and determine if it is suggestive of one being a positive feedback, a negative feedback, or neutral.\n",
    "\n",
    "Senti_Mend, in this version, uses two sentiment tools: swn and vader. Edit sent_mend.conf and choose the proper tool by updating 'algo=' parameter, e.g.\n",
    "\n",
    "    [sentiment]\n",
    "    algo=\"swn\"\n",
    "\n",
    "Below shows how the analysis is taken for swn:\n",
    "\n",
    "**First**, we rely on the following  'sklearn.feature_extraction.text.TfidfVectorizer' module to help with the following functionalities:\n",
    "\n",
    "1. Tokenize - split the comments into terms (words)\n",
    "\n",
    "2. Convert the terms into lowercase\n",
    "\n",
    "3. Use sublinear-tf scaling in place of just term frequency\n",
    "\n",
    "4. Use of L2-norm ( may not have effect )\n",
    "\n",
    "5. Use of stopwords\n",
    "\n",
    "6. Use of IDF and smoothing IDF (may not be required for weights)\n",
    "\n",
    "7. Use both unigram and bigram\n",
    "\n",
    "8. Exclude numeric\n",
    "\n",
    "9. Finally, limit features to maximum of 3000\n",
    "\n",
    "**Second**, we rely on 'nltk.pos_tag' module to associate each term with pattern-of-speech tags.\n",
    "\n",
    "**Third**, we rely on 'nltk.stem.wordnet.WordNetLemmatizer' module to help with lemmatizing words. Because wordnetlemmatizer requires that each word needs the POS tag, then pos-tagging has to come first.\n",
    "\n",
    "The term 'loving' cannot be lemmatized without a pos-tag:\n",
    "<block>\n",
    "<pre>\n",
    "nltk.stem.WordNetLemmatizer().lemmatize('loving')\n",
    "'loving'\n",
    "\n",
    "nltk.stem.WordNetLemmatizer().lemmatize('loving', 'v')\n",
    "'love'\n",
    "</pre>\n",
    "</block>\n",
    "\n",
    "Note: Edit sent_mend.conf to and set \"Lemmatize_first\" to \"True\" if you want to lemmatize terms before taking pos-tags.\n",
    "\n",
    "**Fourth**, we rely on 'nltk.corpus.sentiwordnet' module to get the sentiment weight against the given term and pos-tag:\n",
    "\n",
    "<block>\n",
    "<pre>\n",
    "senti = swn.senti_synset('happy.a.1') \n",
    "print(senti.pos_score())\n",
    "print(senti.neg_score())\n",
    "print(senti.obj_score())\n",
    "\n",
    "&lt;happy.a.01: PosScore=0.875 NegScore=0.0&gt;\n",
    "0.875\n",
    "0.0\n",
    "0.125\n",
    "</pre>\n",
    "</block>\n",
    "\n",
    "### Computing for precision, recall, F1\n",
    "<block>\n",
    "<pre>\n",
    "$ ./senti_mend.py -a\n",
    "\n",
    "Precision-Recall analysis  ...\n",
    "\n",
    "       ------- SENTIMENT ----------------\n",
    "S            POS         NEG\n",
    "C POS        266    |      22\n",
    "O      ----------------------------------\n",
    "R NEG         37    |      11\n",
    "E      ----------------------------------\n",
    "\n",
    "**Precision:**  0.88\n",
    "**Recall:**  0.92\n",
    "**F1-MEASURE:**  0.9\n",
    "</block>\n",
    "</pre>\n",
    "\n",
    "### Test a comment\n",
    "\n",
    "$ ./senti_mend.py -e \"i am not happy\"\n",
    "\n",
    "Evaluating ...\n",
    "\n",
    "Negative\n",
    "\n",
    "$ ./senti_mend.py -e \"i am happy\"\n",
    "\n",
    "Evaluating ...\n",
    "\n",
    "Positive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations and Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The sentiment analysis algorithm at the moment does not classify objectivity vs subjectivity and only assumes subjectivity and polarity (positive feedback vs negative feedback). \n",
    "\n",
    "* POS-tags for words from nltk.stem.wordnet.WordNetLemmatizer may not always match those POS-tags from nltk.corpus.sentiwordnet, e.g. love (n) does not equate to love(v)\n",
    "\n",
    "* The algorithm does not consider collocation at this moment.\n",
    "\n",
    "* We will be looking at nltk.sentiment.vader for Sentiment Insensity to see if it boosts polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## licensing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is released under the terms of the MIT Open Source License. View LICENSE.txt for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
